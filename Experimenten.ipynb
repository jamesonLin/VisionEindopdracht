{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eindopdracht Vision\n",
    "In dit project onderzoek ik de impact van verschillende activatiefuncties op de nauwkeurigheid van een convolutioneel neuraal netwerk (CNN) voor beeldclassificatie en bounding box voorspellingen met TensorFlow. Activatiefuncties zijn cruciaal omdat ze niet-lineaire transformaties toepassen op neuronuitvoer, waardoor complexe patronen in data kunnen worden gemodelleerd.\n",
    "\n",
    "Het doel is om te bepalen welke activatiefunctie(s) het beste presteren voor mijn specifieke taken van beeldclassificatie en het voorspellen van bounding boxes. Ik zal veelgebruikte functies zoals ReLU, Sigmoid, Softmax en Swish vergelijken om te zien welke de hoogste nauwkeurigheid bereiken bij het classificeren van afbeeldingen en het voorspellen van bounding boxes. Daarnaast onderzoek ik hoe variaties in inputafbeeldingen (zoals zwart-wit conversie, rotatie en andere augmentaties) de modelprestaties beïnvloeden.\n",
    "\n",
    "Deze experimenten zullen niet alleen de prestaties van mijn CNN optimaliseren, maar ook inzicht verschaffen in hoe activatiefuncties en variaties in input gezamenlijk de algehele nauwkeurigheid van het model voor beeldclassificatie en bounding box voorspellingen beïnvloeden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Activatiefuncties zijn essentieel in neurale netwerken omdat ze bepalen of een neuron moet worden geactiveerd op basis van zijn input naar het netwerk. Deze functies gebruiken wiskundige bewerkingen om te beslissen of de input belangrijk is voor de voorspelling. Niet-lineaire activatiefuncties stellen neurale netwerken in staat complexe patronen te leren die vaak voorkomen in echte gegevens, in tegenstelling tot lineaire functies die beperkt zijn in hun vermogen om dergelijke patronen te vangen.\n",
    "\n",
    "Data augmentatie is een krachtig middel tegen overfitting in machine learning-modellen, met name in computer vision. Door nieuwe trainingsvoorbeelden te genereren via transformaties van bestaande data, vergroot data augmentatie effectief de omvang en diversiteit van de trainingsdataset. Hierdoor kunnen modellen beter generaliseren naar nieuwe, ongeziene data zonder terug te hoeven keren naar kostbare datacollectie. Dit maakt data augmentatie een kosteneffectieve oplossing voor het verbeteren van de prestaties en robuustheid van machine learning-modellen in diverse toepassingsgebieden zoals beeldherkenning en automatisering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## methodebeschrijving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "TRAINPATH = 'dataset/train/'\n",
    "VALIDPATH = 'dataset/valid/'\n",
    "TESTPATH = 'dataset/test/'\n",
    "NEWPATH = 'dataset/new/'\n",
    "\n",
    "def CraeteLabelMap(path):\n",
    "    annotations = pd.read_csv(path + 'annotation.csv')\n",
    "    # Map label strings to integer labels\n",
    "    labelMap = {}\n",
    "    unique_labels = set(annotations['class'])\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        labelMap[label] = i\n",
    "    return labelMap\n",
    "    \n",
    "def readData(path, labelMap):\n",
    "    target_size = (224, 224)\n",
    "    annotations = pd.read_csv(path + 'annotation.csv')\n",
    "\n",
    "    X_img = []\n",
    "    y_labels = []\n",
    "    y_bboxes = []\n",
    "\n",
    "    for i, annotation in annotations.iterrows():\n",
    "        image_path = annotation['filename']\n",
    "        labels = annotation['class']\n",
    "        xmin = annotation['xmin']\n",
    "        ymin = annotation['ymin']\n",
    "        xmax = annotation['xmax']\n",
    "        ymax = annotation['ymax']\n",
    "\n",
    "        # Preprocess the image\n",
    "        image = Image.open(path + image_path)\n",
    "        image = image.resize(target_size)\n",
    "        image_data = np.array(image, dtype=np.float32)\n",
    "        image_data /= 255.0\n",
    "\n",
    "        # Normalize bounding box coordinates\n",
    "        height, width, channels = image_data.shape\n",
    "        xmin_norm = xmin / width\n",
    "        ymin_norm = ymin / height\n",
    "        xmax_norm = xmax / width\n",
    "        ymax_norm = ymax / height\n",
    "        \n",
    "        X_img.append(image_data)\n",
    "        y_labels.append(labelMap[labels])\n",
    "        y_bboxes.append([xmin_norm, ymin_norm, xmax_norm, ymax_norm])\n",
    "\n",
    "    X_img = np.array(X_img)\n",
    "    y_labels = np.array(y_labels)\n",
    "    y_bboxes = np.array(y_bboxes)\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    Labels_cls = to_categorical(y_labels, NUM_CLASSES)\n",
    "\n",
    "    return X_img, Labels_cls, y_bboxes\n",
    "\n",
    "labelMap = CraeteLabelMap(TRAINPATH)\n",
    "\n",
    "trainImg, trainLabels, trainbboxes = readData(TRAINPATH, labelMap)\n",
    "validImg, validLabels, validbboxes = readData(VALIDPATH, labelMap)\n",
    "testImg, testLabels, testbboxes = readData(TESTPATH, labelMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CraeteLabelMap(path): Deze functie leest de annotatie CSV-bestand en maakt een map van unieke labels naar integerwaarden.\n",
    "* readData(path, labelMap): Deze functie leest de afbeeldingen en annotaties, schaalt de afbeeldingen naar 224x224 pixels, normaliseert de bounding box coördinaten en converteert de labels naar one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentImages(images, labels, bboxes):\n",
    "    augmentedImages = []\n",
    "    augmentedLabels = []\n",
    "    augmentedBboxes = []\n",
    "\n",
    "    for img, label, bbox in zip(images, labels, bboxes):\n",
    "        # Original image\n",
    "        augmentedImages.append(img)\n",
    "        augmentedLabels.append(label)\n",
    "        augmentedBboxes.append(bbox)\n",
    "        \n",
    "        # Grayscale image\n",
    "        gray_img = np.mean(img, axis=2, keepdims=True)\n",
    "        gray_img = np.repeat(gray_img, 3, axis=2)\n",
    "        augmentedImages.append(gray_img)\n",
    "        augmentedLabels.append(label)\n",
    "        augmentedBboxes.append(bbox)\n",
    "\n",
    "        # # Inverted image\n",
    "        # inverted_img = 1.0 - img\n",
    "        # augmentedImages.append(inverted_img)\n",
    "        # augmentedLabels.append(label)\n",
    "        # augmentedBboxes.append(bbox)\n",
    "        \n",
    "        # Rotate the image by 90 degrees\n",
    "        rotated_img = np.array(Image.fromarray((img * 255).astype(np.uint8)).rotate(90)) / 255.0\n",
    "        augmentedImages.append(rotated_img)\n",
    "        augmentedLabels.append(label)\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        # Swap and adjust coordinates for 90-degree rotation\n",
    "        new_xmin = ymin  # New xmin = old ymin\n",
    "        new_ymin = 1 - xmax  # New ymin = 1 - old xmax\n",
    "        new_xmax = ymax  # New xmax = old ymax\n",
    "        new_ymax = 1 - xmin  # New ymax = 1 - old xmin\n",
    "        augmentedBboxes.append([new_xmin, new_ymin, new_xmax, new_ymax])\n",
    "        \n",
    "\n",
    "    return np.array(augmentedImages), np.array(augmentedLabels), np.array(augmentedBboxes)\n",
    "\n",
    "augmentedTrainImg, augmentedTrainLabels, augmentedTrainbboxes = augmentImages(trainImg, trainLabels, trainbboxes)\n",
    "augmentedValidImg, augmentedValidLabels, augmentedValidbboxes = augmentImages(validImg, validLabels, validbboxes)\n",
    "augmentedTestImg, augmentedTestLabels, augmentedTestbboxes = augmentImages(testImg, testLabels, testbboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* augment_images(images, labels, bboxes): Deze functie voegt nieuwe varianten van de afbeeldingen toe door grijswaardenconversie en rotatie toe te passen, en past de bijbehorende bounding box coördinaten aan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    preModel = Path(\"models/softmax.h5\")\n",
    "    if preModel.is_file():\n",
    "        # load trained model\n",
    "        model = load_model('models/softmax.h5')\n",
    "        return model\n",
    "    else:\n",
    "        # Define input tensor\n",
    "        inputs = Input(shape=(224, 224, 3))\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        \n",
    "        # Define the classification prediction head\n",
    "        classification = Flatten()(x)\n",
    "        classification = Dense(256, activation=\"relu\")(classification)\n",
    "        classification = Dropout(0.5)(classification)\n",
    "        class_output = Dense(NUM_CLASSES, activation=\"softmax\", name=\"class_output\")(classification)\n",
    "        \n",
    "        # Define the bounding box prediction head\n",
    "        bbox = Flatten()(x)\n",
    "        bbox = Dense(256, activation=\"relu\")(bbox)\n",
    "        bbox = Dropout(0.5)(bbox)\n",
    "        bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(bbox)\n",
    "        \n",
    "        \n",
    "        # Define the model with input and output layers\n",
    "        model = Model(inputs=inputs, outputs=(class_output, bbox_output))\n",
    "        \n",
    "        losses = {\n",
    "            'class_output': 'categorical_crossentropy',\n",
    "        \t'bbox_output': 'mean_squared_error'\n",
    "        }\n",
    "        \n",
    "        metrics={\n",
    "            'class_output': 'accuracy',\n",
    "            'bbox_output': 'accuracy'\n",
    "        }\n",
    "        \n",
    "        trainTargets = {\n",
    "        \t\"class_output\": trainLabels,\n",
    "        \t\"bbox_output\": trainbboxes\n",
    "            # \"class_output\": augmentedTrainLabels,\n",
    "        \t# \"bbox_output\": augmentedTrainbboxes\n",
    "        }\n",
    "        validTargets = {\n",
    "        \t\"class_output\": validLabels,\n",
    "        \t\"bbox_output\": validbboxes\n",
    "            # \"class_output\": augmentedValidLabels,\n",
    "        \t# \"bbox_output\": augmentedValidbboxes\n",
    "        }\n",
    "        \n",
    "        # Compile the model with categorical_crossentropy, mean_squared_error and Adam optimizer\n",
    "        model.compile(loss=losses, optimizer='adam', metrics=metrics)\n",
    "        \n",
    "        # Train the model on the training data and validation on validation data\n",
    "        checkpoint = ModelCheckpoint('models/softmax.h5', monitor='bbox_output_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "        model.fit(trainImg, trainTargets, epochs=150, batch_size=50, validation_data=(validImg, validTargets), callbacks=[checkpoint])\n",
    "        # model.fit(augmentedTrainImg, trainTargets, epochs=150, batch_size=16, validation_data=(augmentedValidImg, validTargets), callbacks=[checkpoint])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def testModel(model):\n",
    "    testTargets = {\n",
    "        \"class_output\": testLabels,\n",
    "        \"bbox_output\": testbboxes\n",
    "        # \"class_output\": augmentedTestLabels,\n",
    "        # \"bbox_output\": augmentedTestbboxes\n",
    "    }\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_bbox_loss, test_class_loss, test_bbox_acc, test_class_acc = model.evaluate(testImg, testTargets, verbose=0)\n",
    "\n",
    "    # Print the test set metrics\n",
    "    print('Test set loss: ', test_loss)\n",
    "    print('Test set bounding box loss: ', test_bbox_loss)\n",
    "    print('Test set class loss: ', test_class_loss)\n",
    "    print('Test set bounding box accuracy: ', test_bbox_acc)\n",
    "    print('Test set class accuracy: ', test_class_acc)\n",
    "\n",
    "\n",
    "model = getModel()\n",
    "testModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* getModel(): Deze functie definieert de architectuur van het CNN, bestaande uit convolutionele en max-pooling lagen, gevolgd door aparte dense lagen voor classificatie en bounding box voorspelling. Het model wordt gecompileerd met 'categorical_crossentropy' voor classificatie en 'mean_squared_error' voor bounding box voorspelling, en getraind op de trainingsdata.\n",
    "* testModel(model): Deze functie evalueert het getrainde model op de testset en print de verlieswaarden en nauwkeurigheden voor zowel classificatie als bounding box voorspelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_bbox(bbox, origSize, resSize):\n",
    "    scale_x = origSize[0] / resSize\n",
    "    scale_y = origSize[1] / resSize\n",
    "\n",
    "    xNorm, yNorm, wNorm, hNorm = bbox\n",
    "    xmin = xNorm * (origSize[0] / scale_x)\n",
    "    ymin = yNorm * (origSize[1] / scale_y)\n",
    "    xmax = wNorm * (origSize[0] / scale_x)\n",
    "    ymax = hNorm * (origSize[1] / scale_y)\n",
    "\n",
    "    return (xmin, ymin, xmax, ymax)\n",
    "\n",
    "def scaleBbox(bbox, origSize, resSize):\n",
    "    # Calculate scaling factor\n",
    "    scaleX = resSize[0] / origSize[0]\n",
    "    scaleY = resSize[1] / origSize[1]\n",
    "\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xminScaled = xmin * scaleX\n",
    "    yminScaled = ymin * scaleY\n",
    "    xmaxScaled = xmax * scaleX\n",
    "    ymaxScaled = ymax * scaleY\n",
    "\n",
    "    return (xminScaled, yminScaled, xmaxScaled, ymaxScaled)\n",
    "\n",
    "def readNewImages(image_dir):\n",
    "    target_size = (224, 224)\n",
    "    X_img = []\n",
    "\n",
    "    # List all image files\n",
    "    image_files = [file for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
    "    \n",
    "    # Shuffle the list randomly\n",
    "    np.random.shuffle(image_files)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image = Image.open(os.path.join(image_dir, image_file))\n",
    "        image = image.resize(target_size)\n",
    "        image_data = np.array(image, dtype=np.float32)\n",
    "        image_data /= 255.0\n",
    "\n",
    "        X_img.append(image_data)\n",
    "\n",
    "    X_img = np.array(X_img)\n",
    "    return X_img\n",
    "\n",
    "# Load the new data\n",
    "newImg = readNewImages(NEWPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* unnormalize_bbox(bbox, origSize, resSize): Deze functie schaalt genormaliseerde bounding box-coördinaten terug naar originele afmetingen.\n",
    "* scaleBbox(bbox, origSize, resSize): Deze functie schaalt bounding box-coördinaten van originele afmetingen naar een ander resolutieniveau.\n",
    "* readNewImages(image_dir): Deze functie leest nieuwe afbeeldingen in vanuit een opgegeven map en past dezelfde voorverwerking toe als bij de trainings- en testdatasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img, labelMap):\n",
    "    # Predict bounding boxes on the new data\n",
    "    pred_labels, pred_bboxes = model.predict(img)\n",
    "\n",
    "    orig_size = (1920, 1200)\n",
    "    res_size = 224\n",
    "    bboxes = [unnormalize_bbox(bbox, orig_size, res_size) for bbox in pred_bboxes]\n",
    "    img_size = (224, 224)\n",
    "    bboxScaled = [scaleBbox(bbox, orig_size, img_size) for bbox in bboxes]\n",
    "\n",
    "    labelMap = {v: k for k, v in labelMap.items()}\n",
    "\n",
    "    # Generate plot objects for each image and display them one by one\n",
    "    for i in range(len(img)):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # Ensure the image has the correct shape\n",
    "        current_img = img[i]\n",
    "        \n",
    "        if current_img.shape == (3,):  # If it has shape (3,), assume grayscale and reshape\n",
    "            current_img = current_img.reshape(current_img.shape + (1,))\n",
    "\n",
    "        lbl = np.argmax(pred_labels[i], axis=-1)\n",
    "        ax.imshow(current_img)  # Use the reshaped image\n",
    "        ax.axis('off')\n",
    "        label_name = labelMap[lbl] \n",
    "        xmin, ymin, xmax, ymax = bboxScaled[i]\n",
    "        ax.text(xmin, ymin, label_name, fontsize=10, color='red')\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='r')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Display the plot in the notebook\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Wait for user input (press Enter) to continue to the next image\n",
    "        input(\"Press Enter to continue to the next image...\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Call the function\n",
    "prediction(newImg, labelMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* prediction(img, labelMap): Deze functie maakt voorspellingen met behulp van het opgegeven model op nieuwe afbeeldingen en visualiseert de resultaten met behulp van bounding boxes en voorspelde klasselabels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Evaluatie van Activatiefuncties voor Classificatie\n",
    "Dit experiment evalueert de invloed van verschillende activatiefuncties (softmax, sigmoid en swish) op de boundingbox en classificatieprestaties van het CNN-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax\n",
    "De softmax-functie transformeert een vector van getallen naar waarden tussen 0 en 1, waarbij de som van deze waarden gelijk is aan 1. Hierdoor kan de uitvoer worden geïnterpreteerd als de kans dat een specifieke invoer tot een bepaalde klasse behoort.\n",
    "\n",
    "De softmax-functie kan worden gedefinieerd als:\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\n",
    "$$\n",
    "\n",
    "Waarbij \\( x_i \\) de \\( i \\)-waarde in de inputvector is en \\( n \\) de dimensie van de vector is.\n",
    "\n",
    "De Softmax-activatiefunctie wordt gebruikt in de output laag voor classificatie. De Softmax-activatiefunctie berekent de relatieve waarschijnlijkheden voor welke klasse het zou zijn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensor\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Convolutional layers\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Define the classification prediction head\n",
    "classification = Flatten()(x)\n",
    "classification = Dense(256, activation=\"relu\")(classification)\n",
    "classification = Dropout(0.5)(classification)\n",
    "class_output = Dense(NUM_CLASSES, activation=\"softmax\", name=\"class_output\")(classification)\n",
    "\n",
    "# Define the bounding box prediction head\n",
    "bbox = Flatten()(x)\n",
    "bbox = Dense(256, activation=\"relu\")(bbox)\n",
    "bbox = Dropout(0.5)(bbox)\n",
    "bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment_Image/softmax_predict.png\" alt=\"softmax_predict\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment_Image/softmax_evaluate1_train.png\" alt=\"softmax_train\" width=\"500\" heigh=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid\n",
    "Sigmoid zet de inputwaarde om naar een waarde tussen 0 en 1. Deze omzetting maakt het mogelijk om de uitvoer te interpreteren als de kans dat een gegeven invoer tot een bepaalde klasse behoort. Als de uitvoerwaarde dichter bij 0 ligt, wordt de invoer toegewezen aan de ene klasse, terwijl een waarde dichter bij 1 de toewijzing aan een andere klasse aanduidt. Dit maakt de sigmoid-functie ideaal voor binaire classificatie.\n",
    "\n",
    "De wiskundige formule van de sigmoid-functie is:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "Hier is \\( x \\)  de inputwaarde.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensor\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# # Convolutional layers\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Define the classification and bounding box prediction heads\n",
    "classification = Flatten()(x)\n",
    "classification = Dense(256, activation=\"relu\")(classification)\n",
    "classification = Dropout(0.5)(classification)\n",
    "class_output = Dense(NUM_CLASSES, activation=\"sigmoid\", name=\"class_output\")(classification)\n",
    "\n",
    "bbox = Flatten()(x)\n",
    "bbox = Dense(256, activation=\"relu\")(bbox)\n",
    "bbox = Dropout(0.5)(bbox)\n",
    "bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment_Image/sigmoid_predict2.png\" alt=\"sigmoid_predict2\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment_Image/sigmoid_evaluate1_train.png\" alt=\"sigmoid_train\" width=\"500\" heigh=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### swish\n",
    "\n",
    "De swish-functie kan worden gedefinieerd als:\n",
    "\n",
    "$$f(x) = x \\cdot \\sigma(x)$$\n",
    "$$\\text{where} \\quad \\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensor\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# # Convolutional layers\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Define the classification and bounding box prediction heads\n",
    "classification = Flatten()(x)\n",
    "classification = Dense(256, activation=\"swish\")(classification)\n",
    "classification = Dropout(0.5)(classification)\n",
    "class_output = Dense(NUM_CLASSES, activation=\"sigmoid\", name=\"class_output\")(classification)\n",
    "\n",
    "bbox = Flatten()(x)\n",
    "bbox = Dense(256, activation=\"swish\")(bbox)\n",
    "bbox = Dropout(0.5)(bbox)\n",
    "bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"experiment_Image/swish_predict.png\" alt=\"swish_predict\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment_iamge_fix/swish_softmax_evaluate1_train.png\" alt=\"swish_softmax_evaluate1_train\" width=\"500\" heigh=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment_Image/Class_accuracy.png\" alt=\"Class_accuracy\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment_Image/Bbox_accuracy.png\" alt=\"Bbox_accuracy\" width=\"500\" heigh=\"500\"/>\n",
    "\n",
    "Uit de resultaten blijkt dat Softmax en Sigmoid vergelijkbare prestaties leveren voor classificatie, terwijl Swish aanzienlijk minder goed presteert voor zowel classificatie als het voorspellen van bounding boxes. Dit suggereert dat Softmax de voorkeur verdient voor classificatiedoeleinden, vooral in combinatie met de ReLU-activatiefunctie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Augments\n",
    "In dit experiment onderzoeken we de impact van verschillende beeldaugmentaties op de nauwkeurigheid van het model. We zullen het model trainen met drie verschillende vormen van augmentaties: grayscale, rotatie en inverted images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment2_Image/grayscale.png\" alt=\"grayscale\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment2_Image/inverted.png\" alt=\"inverted\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment2_Image/grayscale_invert_evaluate.png\" alt=\"grayscale_invert_evaluate\" width=\"500\" heigh=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier hebben we het model getraind met zowel de originele afbeeldingen als met grayscale en inverted versies ervan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment2_Image/grayscale.png\" alt=\"grayscale\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment2_Image/rotate.png\" alt=\"rotate\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment2_Image/grayscale_rotate_evaluate.png\" alt=\"grayscale_rotate_evaluate\" width=\"500\" heigh=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"experiment2_Image/Class_accuracy.png\" alt=\"Class_accuracy\" width=\"500\" heigh=\"500\"/>\n",
    "<img src=\"experiment2_Image/bbox_accuracy.png\" alt=\"bbox_accuracy\" width=\"500\" heigh=\"500\"/>\n",
    "\n",
    "Uit de resultaten blijkt dat de toevoeging van augmentaties een variërende invloed heeft op de nauwkeurigheid van het model. Specifiek zien we dat de combinatie van grayscale en rotatie resulteert in een verbetering van de classificatienauwkeurigheid. Echter, wanneer grayscale wordt gecombineerd met inverted images, vertoont de classificatienauwkeurigheid een lichte afname in vergelijking met het model zonder augmentaties. Wat betreft de bounding box-nauwkeurigheid laten beide combinaties een afname zien ten opzichte van het basismodel zonder augmentaties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## literatuurlijst\n",
    "1. Adrian Rosebrock *Object detection: Bounding box regression with Keras, TensorFlow, and Deep Learning* 2020.\n",
    "   - URL: [https://pyimagesearch.com/2020/10/05/object-detection-bounding-box-regression-with-keras-tensorflow-and-deep-learning/](https://pyimagesearch.com/2020/10/05/object-detection-bounding-box-regression-with-keras-tensorflow-and-deep-learning/)\n",
    "\n",
    "2. Adrian Rosebrock *Multi-class object detection and bounding box regression with Keras, TensorFlow, and Deep Learning* 2020.\n",
    "   - URL: [https://pyimagesearch.com/2020/10/12/multi-class-object-detection-and-bounding-box-regression-with-keras-tensorflow-and-deep-learning/](https://pyimagesearch.com/2020/10/12/multi-class-object-detection-and-bounding-box-regression-with-keras-tensorflow-and-deep-learning/)\n",
    "\n",
    "3. Rohit Thakur *Step by step VGG16 implementation in Keras for beginners* 2019.\n",
    "   - URL: [https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c](https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c)\n",
    "\n",
    "4. Rohit Thakur *Beginner’s Guide to VGG16 Implementation in Keras* 2023.\n",
    "   - URL: [https://builtin.com/machine-learning/vgg16](https://builtin.com/machine-learning/vgg16)\n",
    "\n",
    "5. Shipra Saxena *Introduction to Softmax for Neural Network* 2023.\n",
    "   - URL: [https://www.analyticsvidhya.com/blog/2021/04/introduction-to-softmax-for-neural-network/](https://www.analyticsvidhya.com/blog/2021/04/introduction-to-softmax-for-neural-network/)\n",
    "\n",
    "6. Pragati Baheti *Activation Functions in Neural Networks [12 Types & Use Cases]* 2021\n",
    " - URL: [https://www.v7labs.com/blog/neural-networks-activation-functions](https://www.v7labs.com/blog/neural-networks-activation-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bijlage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd1e3078beafa9e276d591f345d7c1db12f301969f08477f90f9da9b3ee9715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
